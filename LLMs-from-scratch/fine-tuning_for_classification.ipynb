{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading and unzipping the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "url =\"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
    "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
    "        return\n",
    "\n",
    "    # Downloading the file\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "\n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    # Add .tsv file extension\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(data_file_path,sep=\"\\t\",header=None, names=[\"Label\",\"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>ham</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>ham</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>ham</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>ham</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>spam</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>spam</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "4307   ham  Awww dat is sweet! We can think of something t...\n",
       "4138   ham                             Just got to  &lt;#&gt;\n",
       "4831   ham  The word \"Checkmate\" in chess comes from the P...\n",
       "4461   ham  This is wishing you a great day. Moji told me ...\n",
       "5440   ham      Thank you. do you generally date the brothas?\n",
       "...    ...                                                ...\n",
       "5537  spam  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540  spam  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "\n",
    "    # Count the instance of \"spam\"\n",
    "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
    "\n",
    "    # Randomly sample \"ham\" instances to match the number of \"spam\" instances\n",
    "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
    "\n",
    "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4307</th>\n",
       "      <td>0</td>\n",
       "      <td>Awww dat is sweet! We can think of something t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0</td>\n",
       "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>0</td>\n",
       "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4461</th>\n",
       "      <td>0</td>\n",
       "      <td>This is wishing you a great day. Moji told me ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5440</th>\n",
       "      <td>0</td>\n",
       "      <td>Thank you. do you generally date the brothas?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>1</td>\n",
       "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5540</th>\n",
       "      <td>1</td>\n",
       "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>1</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "4307      0  Awww dat is sweet! We can think of something t...\n",
       "4138      0                             Just got to  &lt;#&gt;\n",
       "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
       "4461      0  This is wishing you a great day. Moji told me ...\n",
       "5440      0      Thank you. do you generally date the brothas?\n",
       "...     ...                                                ...\n",
       "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
       "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
       "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
       "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
       "5567      1  This is the 2nd time we have tried 2 contact u...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_frac, validation_frac):\n",
    "    # Shuffle the entire DataFrame\n",
    "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\n",
    "    # Calculate split indices\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    validation_end = train_end + int(len(df) * validation_frac)\n",
    "\n",
    "    # Split the DataFrame\n",
    "    train_df = df[:train_end]\n",
    "    validation_df = df[train_end:validation_end]\n",
    "    test_df = df[validation_end:]\n",
    "\n",
    "    return train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "# Test size is implied to be 0.2 as the remainder\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "validation_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create dataloaders : 将最长的文本作为训练数据并增加padding补全不够的短文本字符"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id = 50256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        #pre tokenize texts\n",
    "        self.encoded_texts = [\n",
    "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "        ]\n",
    "\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate sequences if they are longer than max_length\n",
    "            self.encoded_texts = [\n",
    "                encoded_text[:self.max_length] for encoded_text in self.encoded_texts\n",
    "            ]\n",
    "        \n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"Label\"]\n",
    "\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def _longest_encoded_length(self):\n",
    "        max_length = 0\n",
    "        for encoded_text in self.encoded_texts:\n",
    "            encoded_length = len(encoded_text)\n",
    "            if encoded_length > max_length:\n",
    "                max_length = encoded_length \n",
    "\n",
    "        return max_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\n",
    "    csv_file=\"train.csv\",\n",
    "    max_length=None,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\n",
    "    csv_file=\"validation.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "test_dataset = SpamDataset(\n",
    "    csv_file=\"test.csv\",\n",
    "    max_length=train_dataset.max_length,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后创建daterloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    drop_last=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "19 validation batches\n",
      "38 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def download_and_load_gpt2(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)\n",
    "\n",
    "    # Load settings and params\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "    params = load_gpt2_params_from_tf_ckpt(tf_ckpt_path, settings)\n",
    "\n",
    "    return settings, params\n",
    "\n",
    "\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            # Get the total file size from headers, defaulting to 0 if not present\n",
    "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "            # Check if file exists and has the same size\n",
    "            if os.path.exists(destination):\n",
    "                file_size_local = os.path.getsize(destination)\n",
    "                if file_size == file_size_local:\n",
    "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                    return\n",
    "\n",
    "            # Define the block size for reading the file\n",
    "            block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "            # Initialize the progress bar with total file size\n",
    "            progress_bar_description = os.path.basename(url)  # Extract filename from URL\n",
    "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "                # Open the destination file in binary write mode\n",
    "                with open(destination, \"wb\") as file:\n",
    "                    # Read the file in chunks and write to destination\n",
    "                    while True:\n",
    "                        chunk = response.read(block_size)\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        file.write(chunk)\n",
    "                        progress_bar.update(len(chunk))  # Update progress bar\n",
    "    except urllib.error.HTTPError:\n",
    "        s = (\n",
    "            f\"The specified URL ({url}) is incorrect, the internet connection cannot be established,\"\n",
    "            \"\\nor the requested file is temporarily unavailable.\\nPlease visit the following website\"\n",
    "            \" for help: https://github.com/rasbt/LLMs-from-scratch/discussions/273\")\n",
    "        print(s)\n",
    "\n",
    "\n",
    "# Alternative way using `requests`\n",
    "\"\"\"\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def load_gpt2_params_from_tf_ckpt(ckpt_path, settings):\n",
    "    # Initialize parameters dictionary with empty blocks for each layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "\n",
    "    # Iterate over each variable in the checkpoint\n",
    "    for name, _ in tf.train.list_variables(ckpt_path):\n",
    "        # Load the variable and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(ckpt_path, name))\n",
    "\n",
    "        # Process the variable name to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # Skip the 'model/' prefix\n",
    "\n",
    "        # Identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "\n",
    "        # Recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "\n",
    "        # Assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "# from gpt_download import download_and_load_gpt2\n",
    "from previous_chapters import GPTModel, load_weights_into_gpt\n",
    "\n",
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "#model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from previous_chapters import (\n",
    "    generate_text_simple,\n",
    "    text_to_token_ids,\n",
    "    token_ids_to_text\n",
    ")\n",
    "\n",
    "text_1 = \"Every effort moves you\"\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model = model,\n",
    "    idx = text_to_token_ids(text_1, tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/wk/anaconda3/envs/pytorch/lib/python3.11/site-packages (4.66.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
      "\n",
      "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features = num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 实验发现微调的时候增加别的层进行训练效果也很不错，这里增加了最后一个transformer block,\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "for parm in model.final_norm.parameters():\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs  tensor([[5211,  345,  423,  640]])\n",
      "torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs \", inputs)\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7235,  7.4548],\n",
      "         [-2.2661,  6.6049],\n",
      "         [-3.5983,  3.9902]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(inputs)\n",
    "print(\"Outputs:\\n\", outputs)\n",
    "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token tensor([[-3.5983,  3.9902]])\n"
     ]
    }
   ],
   "source": [
    "# 输出最后一列的概率值\n",
    "print(\"Last output token\",outputs[:,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas  = torch.softmax(outputs[:,-1:], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "    model.eval()\n",
    "    correct_predictions, num_examples= 0, 0\n",
    "\n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches,len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                logits = model(input_batch)[:,-1,:]\n",
    "            predicted_labels = torch.argmax(logits,dim=-1)\n",
    "\n",
    "            num_examples += predicted_labels.shape[0]\n",
    "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "        else:\n",
    "            break\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 46.25%\n",
      "Validation accuracy: 45.00%\n",
      "Test accuracy: 48.75%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# As of this writing, in PyTorch 2.4, the results obtained via CPU and MPS were identical.\n",
    "# However, in earlier versions of PyTorch, you may observe different results when using MPS.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#print(f\"Running on {device} device.\")\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)[:,-1,:]\n",
    "    # 这里只关心最后一个token\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as in chapter 5\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 2.453\n",
      "Validation loss: 2.583\n",
      "Test loss: 2.322\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall the same as `train_model_simple` in chapter 5\n",
    "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                            eval_freq, eval_iter):\n",
    "    # Initialize lists to track losses and examples seen\n",
    "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "    examples_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Calculate accuracy after each epoch\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
    "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as chapter 5\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 2.154, Val loss 2.392\n",
      "Ep 1 (Step 000050): Train loss 0.617, Val loss 0.637\n",
      "Ep 1 (Step 000100): Train loss 0.523, Val loss 0.557\n",
      "Training accuracy: 70.00% | Validation accuracy: 72.50%\n",
      "Ep 2 (Step 000150): Train loss 0.560, Val loss 0.488\n",
      "Ep 2 (Step 000200): Train loss 0.419, Val loss 0.396\n",
      "Ep 2 (Step 000250): Train loss 0.409, Val loss 0.353\n",
      "Training accuracy: 82.50% | Validation accuracy: 85.00%\n",
      "Ep 3 (Step 000300): Train loss 0.333, Val loss 0.321\n",
      "Ep 3 (Step 000350): Train loss 0.343, Val loss 0.311\n",
      "Training accuracy: 87.50% | Validation accuracy: 87.50%\n",
      "Ep 4 (Step 000400): Train loss 0.166, Val loss 0.235\n",
      "Ep 4 (Step 000450): Train loss 0.166, Val loss 0.145\n",
      "Ep 4 (Step 000500): Train loss 0.227, Val loss 0.147\n",
      "Training accuracy: 100.00% | Validation accuracy: 95.00%\n",
      "Ep 5 (Step 000550): Train loss 0.208, Val loss 0.150\n",
      "Ep 5 (Step 000600): Train loss 0.091, Val loss 0.077\n",
      "Training accuracy: 100.00% | Validation accuracy: 97.50%\n",
      "Training completed in 0.54 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 5\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 96.73%\n",
      "Validation accuracy: 97.32%\n",
      "Test accuracy: 96.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
    "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
    "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
    "\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs to the model\n",
    "    input_ids = tokenizer.encode(text)\n",
    "    supported_context_length = model.pos_emb.weight.shape[0]\n",
    "    # Note: In the book, this was originally written as pos_emb.weight.shape[1] by mistake\n",
    "    # It didn't break the code but would have caused unnecessary truncation (to 768 instead of 1024)\n",
    "\n",
    "    # Truncate sequences if they too long\n",
    "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\n",
    "    # Pad sequences to the longest sequence\n",
    "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
    "\n",
    "    # Model inference\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
    "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Return the classified result\n",
    "    return \"spam\" if predicted_label == 1 else \"not spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
    "model.load_state_dict(model_state_dict)\n",
    "text_2 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
