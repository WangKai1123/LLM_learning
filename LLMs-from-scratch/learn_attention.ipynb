{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([\n",
    "    [0.43,0.15,0.89],\n",
    "    [0.55,0.87,0.66],\n",
    "    [0.57,0.85,0.64],\n",
    "    [0.22,0.58,0.33],\n",
    "    [0.77,0.25,0.10],\n",
    "    [0.05,0.80,0.55]\n",
    "])\n",
    "\n",
    "query = inputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意力机制中的Q K V 是 input X 和三个权重矩阵 Wq, Wk, Wv 相乘得到"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_2 = inputs[1]\n",
    "# d_in 和d_out 是GPT 的输入和输出维度，实际上是一样的，为了比较明显，这里设置为不一样的\n",
    "d_in = inputs.shape[1]\n",
    "d_out = 2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize three Matrix\n",
    "torch.manual_seed(123)\n",
    "# 后面的那个参数表示这个参数是训练的时候可以更新的\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in,d_out),requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
